## July.

### Quantization. ###

#### Stable Diffusion Model. ####
- **Softmax** Bias Correction for Quantized Generative Models [https://arxiv.org/abs/2309.01729](https://arxiv.org/abs/2309.01729)
- **PTQ4DM**: Post-training Quantization on Diffusion Models [https://arxiv.org/abs/2211.15736](https://arxiv.org/abs/2211.15736)
- **Q-Diffusion**: Quantizing Diffusion Models [https://arxiv.org/abs/2302.04304](https://arxiv.org/abs/2302.04304)
- **PTQ-D**: Accurate Post-Training Quantization for Diffusion Models. [https://arxiv.org/abs/2305.10657](https://arxiv.org/abs/2305.10657)
- **APQ-DM**: Towards Accurate Post-training Quantization for Diffusion Models [https://arxiv.org/abs/2305.18723](https://arxiv.org/abs/2305.18723)
- **TFMQ-DM**: Temporal Feature Maintenance Quantization for Diffusion Models [https://arxiv.org/abs/2311.16503](https://arxiv.org/abs/2311.16503)
- **QuEST**: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning [https://arxiv.org/abs/2402.03666](https://arxiv.org/abs/2402.03666)

#### Large Language Model. ####
- **QServe**: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving [https://arxiv.org/abs/2405.04532](https://arxiv.org/abs/2405.04532)
- **QuIP**: 2-Bit Quantization of Large Language Models With Guarantees [https://arxiv.org/abs/2307.13304](https://arxiv.org/abs/2307.13304)
- **QuIP#**: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks [https://arxiv.org/abs/2402.04396](https://arxiv.org/abs/2402.04396)

### Language. ###
- C++ **The Cherno** [https://www.youtube.com/@TheCherno](https://www.youtube.com/@TheCherno)

### Swim. ###

### Skate. ###
