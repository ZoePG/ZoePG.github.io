## Aug. ~ Dec.

### Topic. ###
  - **MPQ**
    
### Algorithm. ###
  - [**Softmax**](https://arxiv.org/abs/2309.01729) Bias Correction for Quantized Generative Models
    - distribution-analysis
  - [**PTQ4DM**:](https://arxiv.org/abs/2211.15736) Post-training Quantization on Diffusion Models
  - [**Q-Diffusion**:](https://arxiv.org/abs/2302.04304) Quantizing Diffusion Models
  - [**PTQ-D**:](https://arxiv.org/abs/2305.10657) Accurate Post-Training Quantization for Diffusion Models.
  - [**APQ-DM**:](https://arxiv.org/abs/2305.18723) Towards Accurate Post-training Quantization for Diffusion Models
  - [**TFMQ-DM**:](https://arxiv.org/abs/2311.16503) Temporal Feature Maintenance Quantization for Diffusion Models
  - [**QuEST**:](https://arxiv.org/abs/2402.03666) Low-bit Diffusion Model Quantization via Efficient Selective Finetuning
  - [**QServe**:](https://arxiv.org/abs/2405.04532) W4A8KV4 Quantization and System Co-design for Efficient LLM Serving
    - kernel-code
  - [**QuIP**:](https://arxiv.org/abs/2307.13304) 2-Bit Quantization of Large Language Models With Guarantees
  - [**AQLM**:](https://arxiv.org/abs/2401.06118) Extreme Compression of Large Language Models via Additive Quantization
    - verctor-quantization-TA
  - [**QuIP#**:](https://arxiv.org/abs/2402.04396) Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks
    - verctor-quantization-TB
  - [**LLM-FP4**:](https://arxiv.org/abs/2310.16836) 4-Bit Floating-Point Quantized Transformers

### Project. ###
  - [**The Cherno**](https://www.youtube.com/@TheCherno)
  - **Pylight**
    - onnx
    - gptq
   
### Contest. ###
  - [**12CD/Month**](https://www.stopstalk.com/dashboard)
    - dynamic-topic

### Swim. ###
  - **Freestyle**
    - 12.5+25
  - **Butterfly**
    - 12.5+25
  - **Breaststroke**
    - 25

### Skate. ###
  - **Step Sequence**
    - clockwise-direction
  - **Back Skating**
    - back-C
